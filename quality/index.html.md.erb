---
layout: handbook-page-toc
title: Quality Engineering Department
description: >-
  The Quality Engineering Department enables GitLab to achieve world class
  enterprise grade readiness and empowers product and development teams to ship
  software at scale without sacrificing quality.
---

## On this page
{:.no_toc .hidden-md .hidden-lg}

- TOC
{:toc .hidden-md .hidden-lg}

#### Child Pages

##### [On-boarding](/handbook/engineering/quality/onboarding/)

##### [Guidelines](/handbook/engineering/quality/guidelines/)

##### [Issue triage](/handbook/engineering/quality/issue-triage/)

##### [Wider Community Merge Request triage](/handbook/engineering/quality/merge-request-triage/)

##### [Performance Indicators](/handbook/engineering/quality/performance-indicators/)

##### [Performance and Scalability](/handbook/engineering/quality/performance-and-scalability/)

##### [Project Management](/handbook/engineering/quality/project-management/)

##### [Quad Planning](/handbook/engineering/quality/quad-planning/)

##### [Roadmap](/handbook/engineering/quality/roadmap/)

##### [Test Engineering](/handbook/engineering/quality/test-engineering/)

##### [Triage Operations](/handbook/engineering/quality/triage-operations/)

##### [Risk Mapping](/handbook/engineering/quality/risk-mapping/)

## Our principles

GitLab's Quality is everyone's responsibility. The Quality Department ensures that everyone is aware of what the Quality of the product is, empirically.

- **Foster an environment where Quality is Everyone's responsibility.**
    - We enable product teams in baking quality early in the product development flow process.
    - We are a sounding-board for our end users by making their feedback known to product teams.
    - We are a champion for better software design, promote proper testing practices and bug prevention strategies.
- **Drive test coverage and leverage tests at all [levels](https://docs.gitlab.com/ee/development/testing_guide/testing_levels.html).**
    - We work to ensure that the right tests are run at the right places.
    - We enable product teams to be aware of the test coverage in their domain.
    - We work to enable fast, clear and actionable test reporting.
- **Ensure that teams are efficient and productive.**
    - We build automated solutions to improve Engineering workflow and productivity.
    - We work to ensure reliability in our tooling and tests.
    - We ensure that continuous integration pipelines are efficient with optimal coverage.
    - We continuously improve by reducing test duplications and increasing test stability.
- **We're metrics driven.**
    - We provide clarity to data regarding defects, test stability, efficiency and team health.
    - We ensure the data is actionable and is available transparently to the company and our users.
    - We make metrics-driven optimizations to continuously improve Engineering processes.
    - We use data to improve our test coverage.

## FY22 Direction

The Quality direction for FY22 is to empower GitLab R&D teams and Contributors to deliver with quality at high velocity.

### Test coverage and tooling

- Continue to increase test coverage optimally.
- Continue to improve the reliability of our test suites.
- Completely transition to GitLab Testcases for all QA test coverage.

### Community contributions

- Reduce review and merge time of contributions.
- Add momentum to our [strategy](/company/strategy/#2-build-on-our-open-core-strength) by improving the execution and measurement of [MRARR](/handbook/engineering/quality/performance-indicators/#mrarr).
- Create MR Coach role specialties.
- Improve contribution help-needed task visibility and organize by speciality categories.
- Improve community team metrics and workflow through automation.

### People

- Invest in growing the Quality department team members' skills.
- Take action early from our FY21 engagement results.
- Make progress on hiring in the most needed areas.

### Metrics

- Continue to improve upon our Centralized Engineering handbook dashboards.
- Build out skills and staffing for our Engineering Data team.
- Build out remaining Quality job family performance indicators.

### With GitLab Counterparts

#### Development department

- Make development teams aware of their teams' quality indicators.
- Foster an environment where development teams are productive in contributing test coverage.
- Partner with Development to turn [S1 severity level](https://about.gitlab.com/handbook/engineering/quality/issue-triage/#severity) SLO into SLA.
- Help development teams execute at their best by identifying and mitigating risk in our product development workflow with Quad-planning.

#### UX department

- Partner with UX to prioritize our efforts on time to close of UX bugs and debt.
- Partner with UX to improve awareness of usability metrics by product area.
- Leverage UX early in our product development workflow with Quad-planning.
- Improve visibility of documentation contribution opportunities.

#### Infrastructure department

- Be a champion of corrective actions surfaced from [incident reviews](https://about.gitlab.com/handbook/engineering/infrastructure/incident-review/).
- Ensure timely response in release delivery flow.
- Partner with Infrastructure to improve awareness of GitLab.com incident trends by product area.

#### Security department

- Partner with Security to improve awareness and appropriately prioritize vulnerabilities by product area.
- Impact organizational efforts to shift security left with a focus of proactive AppSec in one product area.
- Implement strategies to more effectively detect and mitigate vulnerabilities prior to production deploy.

#### Support department

- Champion feedback from Support to improve our workflow and test coverage.
- Partner with Support to improve our documentation.

#### Product Division

- Make informed decisions by aligning to our product north star metrics.
- Ensure transparency of test-coverage for product management.
- Improve product management awareness of their engineering teams' metrics and indicators.
- Identify areas to improve usability and SUS scores with UX.
- Prioritize test coverage for SaaS based on business growth.

#### Marketing Division

- Partner with community team to increase the reach and impact of hackathons.
- Partner with community team in creating MR Coach role specialties.

#### Sales Division

- Partner with TAM to efficiently track contributions from customers.
- Enable TAMs to champion and drive-up [MRARR](/handbook/engineering/quality/performance-indicators/#mrarr).
- Build developer certification program.
- Partner with SAs to be productive in deploying demo data.

## OKRs (Current Quarter)

<iframe src="https://app.ally.io/public/LngCHdk3uKSaBuG" class="dashboard-embed" height="1440" width="100%" style="border:none;"> </iframe>

## OKRs (Previous Quarter)

<iframe src="https://app.ally.io/public/uKiFyIu7rH6lz7L" class="dashboard-embed" height="1590" width="100%" style="border:none;"> </iframe>

## Contribution Acceleration Timeline

We aim to increase the focus on our community contributions. Below is a timeline on how we will measure and track this goal.

- **[Unique Community Contributors per Month](/handbook/engineering/quality/performance-indicators/#unique-community-contributors-per-month)**
    - Target to increase to be greater than 150 per month by EOFY22
    - Activities:
        - Partnership with Community Relations and Technical Marketing team.
        - Hold community office hours
        - Hold hackathons
        - Allow running of QA tests from forks
        - Shorten the CI runtime for community contributions (in forks)
- **[Community Coaches per Month](/handbook/engineering/quality/performance-indicators/#community-mr-coaches-per-month)**
    - Target to increase to be greater than 50 per month by EOFY22
    - Activities:
    - Work with Development Department (Christopher L, VP of Development) for volunteers.
    - Work with UX Department (Christie L, VP of UX) Christie for volunteers.
    - Refresh MR coaches as “Community coaches” so non-code review work can be encouraged (design, etc)
    - Launch training materials for coaches
- **[Community Contribution MRs as Features per Month](/handbook/engineering/quality/performance-indicators/#community-contribution-mrs-added-as-features-per-month)**
    - Target to increase by 30% by EOFY22
    - Activities:
        - Encourage features at Community relations hackathons.
        - Published list of feature issues with Marketing team.
- **[Community Contribution MTTM](/handbook/engineering/quality/performance-indicators/#community-contribution-mean-time-to-merge)**
    - Target to decrease to be lower than 10 days by EOFY22
    - Activities:
        - Shorten CI time
        - Improve Community Contribution automation
        - Enable running QA tests on forks
        - Increase number of coaches
        - Partner with `~"group::ecosystem"` to provide feedback to improve contribution tooling (currently GDK).
- **[MRARR](/handbook/engineering/quality/performance-indicators/#mrarr)**
    - Target to increase to 1B MR$ by EOFY23
    - Activities:
        - Improve on measurement
        - Reach out to top tier enterprise customers
        - Partner with TAMs to enlist and facilitate contribution from paid customers
        - Launch contribution materials targeting large enterprises
        - Partner with Community relations team (David P)
        - Maintain a list of known contributors with a mapping to their accounts and the accounts ARR contribution as input to this KPI

## Quality Engineering structure

### Teams within Quality Engineering

##### [Dev QE team](dev-qe-team)

##### [Ops QE team](ops-qe-team)

##### [Fulfillment & Growth QE team](fulfillment-growth-qe-team)

##### [Sec & Enablement QE team](sec-enablement-qe-team)

##### [Engineering Productivity team](engineering-productivity-team)

| Team                           | GitLab.com handle  | Slack channel | Slack handle |
| ------------------------------ | ------------------ | ------------- | ------------ |
| [Dev QE team](dev-qe-team)     | [`@gl-quality/dev-qe`](https://gitlab.com/gl-quality/dev-qe) | [#g_qe_dev](https://gitlab.slack.com/archives/CU90UDHC6) | `@dev-qe-team` |
| [Ops & CI/CD QE team](ops-qe-team) | [`@gl-quality/ops-qe`](https://gitlab.com/gl-quality/ops-qe) | [#g_qe_ops](https://gitlab.slack.com/archives/CUGNRS97V) | `@ops-qe-team` |
| [Sec & Enablement QE team](sec-enablement-qe-team) | [`@gl-quality/enablement-qe`](https://gitlab.com/gl-quality/enablement-qe) | [#g_qe_enablement_secure](https://gitlab.slack.com/archives/CTP7N0PM4) | `@enablement-secure-qe-team` |
| [Fulfillment & Growth QE team](fulfillment-growth-qe-team) | [`@gl-quality/fulfillment-qe`](https://gitlab.com/gl-quality/fulfillment-qe) | [#g_qe_fulfillment_growth](https://gitlab.slack.com/archives/C014UQAC8JW) |`@fulfillment-growth-qe-team` |
| [Engineering Productivity team](engineering-productivity-team) | [`@gl-quality/eng-prod`](https://gitlab.com/gl-quality/eng-prod) | [#g_qe_engineering_productivity](https://gitlab.slack.com/archives/CMA7DQJRX) |`@eng-productivity-team ` |

### Department members

<%
vp_role = 'Vice President of Quality'
director_role = 'Interim Director of Quality Engineering'
roles_regexp = /(Engineer in Test|Engineering Productivity|Quality Engineering|Staff Infrastructure Analyst|Senior Operations Analyst)/
%>

#### Management team

<%= shared_team_members(role_regexps: [/(Vice President of Quality|Interim Director of Quality Engineering|Quality Engineering Manager|Engineering Manager, Engineering Productivity)/i]) %>

#### Individual contributors

<%= stable_counterparts(role_regexp: roles_regexp, direct_manager_role: director_role) %>

### Stable counterparts

Every Software Engineer in Test (SET) takes part in building our product as a DRI in [GitLab's Product Quad DRIs](/handbook/product/product-processes/#pm-em-ux-and-set-quad-dris).
They work alongside Development, Product, and UX in the [Product Development Workflow](/handbook/product-development-flow/#build-phase-1-plan).
As stable counterparts, SETs should be considered critical members of the core team between Product Designers, Engineering Managers and Product Managers.

- SETs should receive invites and participate in all relevant product group collaborations (meeting recordings, retro issues, planning issues, etc).
- SETs should operate proactively, not waiting for other stable counterparts to provide them direction.
The area a Software Engineer in Test is responsible for is defined in the [Product Stages and Groups](/handbook/product/categories/#hierarchy) and part of their title in [team org chart](/company/team/org-chart/).

Every Quality Engineering Manager is aligned with an Engineering Director in the Development Department.
They work at a higher level and align cross-team efforts which maps to a [Development Department section](/handbook/product/categories/#hierarchy).
The area a Quality Engineering Manager is responsible for is defined in the [Product Stages and Groups](/handbook/product/categories/#hierarchy) and part of their title in [team org chart](/company/team/org-chart/).
This is with the exception of the Engineering Productivity team which is based on the [span of control](/company/team/structure/#management-group).

Full-stack Engineering Productivity Engineers develop features both internal and external that improves the efficiency of engineers and development processes.
Their work is separate from the regular release kickoff features per [areas of responsibility](/handbook/engineering/quality/engineering-productivity-team#areas-of-responsibility).

### Staffing planning

We staff our department with the following gearing ratios:

#### Software Engineer in Test

* **Primary Ratio**: 1 Software Engineer in Test per [Product Group](/handbook/product/categories/#hierarchy).
  * This ratio is captured as a department [performance indicator](/handbook/engineering/quality/performance-indicators/#software-engineer-in-test-gearing-ratio).
  * We are improving this ratio by factoring additional facets of each product group and not blanket allocating staffing to every product group. These facets include:
     1. Driver scores (Usage, SMAU, SAM)
     1. Revenue path (ARR, Uptier)
     1. Customer adoption journey
     1. Self-manage & Reference Architecture impact
     1. Must work areas
     1. Development and UX facets (number of Engineers, SUS issues)
  * For more information, please see the [SET Gearing Prioritization Model for more (GitLab Only)](https://docs.google.com/spreadsheets/d/e/2PACX-1vRM5jmGgT5H1kDOi6UwHTbK7PnoPYTYATnLe5HgVkJqe2VvaWo9fKpbnB6gR4vhx3UDby4wUeGwPYEq/pubhtml?gid=2059771943&single=true){:target="_blank"}. With these adjustments, we would be at ~85% of the 1:1 ratio to every product group.
    * Product groups with high complexity may need more than one SET.
    * Newly formed product groups may not have an allocated SET. They may be allocated one in the future.
* Secondary Ratio: Approximately a 1:8 ratio of Software Engineer in Test to Development Department Engineers.

#### Engineering Productivity Engineer

* **Primary Ratio**: 1 Engineering Productivity Engineer per [Product Stage](/handbook/product/categories/#hierarchy).
  * This ratio is captured as a department [performance indicator](/handbook/engineering/quality/performance-indicators/#engineering-productivity-engineer-gearing-ratio).
* Secondary Ratio: Approximately a 1:40 ratio of Engineering Productivity Engineers to Development Department Engineers.

#### Quality Engineering Manager

* **Primary Ratio**: 1 Quality Engineering Manager per [Product Section](/handbook/product/categories/#hierarchy).
  * This ratio is captured as a department [performance indicator](/handbook/engineering/quality/performance-indicators/#quality-engineering-manager-gearing-ratio).
* Secondary Ratio: Approximately a 1:1 ratio of Quality Engineering Manager to Development Department Directors.

## Communication

In addition to GitLab's [communication guidelines](/handbook/communication) and [engineering communication](/handbook/engineering/#communication), we communicate and collaborate actively across GitLab in the following venues:

- [Group Conversation](#group-conversation)
- [Week-in-review](#week-in-review)
- [Department meetings](#department-meetings)
- [Engineering-wide retrospective](#engineering-wide-retrospective)

### Group Conversations

[Group Conversations](/handbook/group-conversations/) or abbreviated as GC for short, runs on an 8-week cadence.
The Quality department has our own, and we also contribute content to the GC presentation slides for our counterpart product sections.

#### Quality Department Group Conversations

This is a company-wide discussion where we highlight achievements, challenges, and progress of the department.
You can look up the historical prep of our group conversations using the [`group-conversation`](https://gitlab.com/gitlab-org/quality/team-tasks/-/issues?label_name%5B%5D=group-conversation) label in our issue tracker.

#### Counterpart Product Group Conversations

Quality Engineering Managers are responsible for contributing Quality-focused content to the GC slides for their counterpart product sections.
At a minimum, details about our related OKRs should be shared, but other info can be shared as appropriate.
In general, aim to keep the slides informative yet brief and few in number, since we do have our own GC during which we can share more details.
Following are some ideas for suggested content.

- OKRs
    - If the GC is in the middle of the quarter, only include current quarter OKRs.
    - If the GC is near the start/end of a quarter, consider including both previous and next quarter OKRs.
- Notable achievements or progress
- Notable gaps or problems

### Week-in-review

By the end of the week, we populate the **Engineering Week-in-Review document** with relevant updates from our department. The agenda is internal only, please search in Google Drive for 'Engineering Week-in-Review'.
Every Monday a reminder is sent to all of engineering in the [#eng-week-in-review](https://gitlab.slack.com/messages/CJWA4E9UG) slack channel to read summarize updates in the google doc.

### Department meetings

We try to have as few meetings as possible. We currently have 3 recurring meetings for the whole department.
Everyone in the Department is free to join and the agenda is available to everyone in the company. Every meeting is also recorded.

1. **Quality Department Bi-Weekly**: This is where the whole department comes together once every 2 weeks to discuss our day-to-day challenges, propose automation framework improvements and catchup on important announcements. This meeting happens in 2 parts to accommodate our team members across multiple timezones.
    - Part 1 - Alternate Wednesday's @1330 PDT (PDT because the majority of the attendees are in the US and we follow daylight savings)
    - Part 2 - Alternate Thursday's @0730 UTC
1. **Quality Engineering Staff Weekly**: This weekly brings together Quality Engineering's management team to discuss directional plans, long-term initiatives, hiring goals and address issues that require attention. This meeting is scheduled for every Wednesday at 1430 UTC (adjusts per PDT).
1. **Quality Department Social Bi-Weekly**: This is where the whole department comes together once every 2 weeks to connect socially with the rest of the department. There is no set agenda and is an open forum for team members to meet and talk freely. This is not mandatory, but is a great way to get to know your fellow team members. This meeting also happens in 2 parts to accommodate our team members across multiple timezones.
    - Part 1 - Alternate Wednesday's 1330 PDT (PDT because the majority of the attendees are in the US and we follow daylight savings)
    - Part 2 - Alternate Thursday's 0730 UTC
1. **Engineering Productivity Team Weekly**: The Engineering Productivity team meets weekly to discuss engineering wide process improvements. This meeting is scheduled for every Tuesday at 1300 UTC.
1. **Team skip-level**: Every team in Quality has a [skip-level 1:1](/handbook/leadership/skip-levels/) with the Director of Quality every 6 weeks. The purpose of this meeting is to help the department leader be a better manager of themselves and direct line managers.

### Engineering-wide retrospective

The Quality team holds an asynchronous retrospective for each release.
The process is automated and notes are captured in [Quality retrospectives](https://gitlab.com/gl-retrospectives/quality/) (GITLAB ONLY)

## Engineering Metrics task process

We track work regarding performance indicators in the [Engineering Metrics](https://gitlab.com/gitlab-com/www-gitlab-com/-/boards/1942495) board.

The purpose of the board is to:

- Define workstream of new engineering KPIs and RPIs.
- Determine order importance of completing each PIs.
- Clearly identify dependency on the data warehouse for GitLab's Data team to assist.

The work effort on Engineering Division and Departments' KPIs/RPIs is currently a shared capacity of the following:

- [Director of Quality](https://gitlab.com/meks)
- [Backend Engineering Manager, Engineering Productivity](https://gitlab.com/kwiebers)
- [Backend Engineer, Engineering Productivity](https://gitlab.com/markglenfletcher)
- [Development Senior Operations Analyst](https://gitlab.com/lmai1).
- [Infrastructure Staff Data Analyst](https://gitlab.com/davis_townsend)

This group also maintains the [Engineering Metrics](/handbook/engineering/metrics/) page.

### DRIs

The [Engineering Metrics](https://gitlab.com/gitlab-com/www-gitlab-com/-/boards/1942495) board is structured by the tasks and asks within each Engineering Departments.

The ownership of the work columns are as follows:

* CTO: [Director of Quality](https://gitlab.com/meks)
* Customer Support Department: [Director of Quality](https://gitlab.com/meks)
* Development Department: [Development Senior Operations Analyst](https://gitlab.com/lmai1)
* Infrastructure Department: [Infrastructure Staff Data Analyst](https://gitlab.com/davis_townsend)
* Quality Department: [Backend Engineering Manager, Engineering Productivity](https://gitlab.com/kwiebers)
* UX Department: [Director of Quality](https://gitlab.com/meks)
* Security Department: [Backend Engineering Manager, Engineering Productivity](https://gitlab.com/kwiebers)

We still need to establish a triage process for open issues or generic issues.

#### DRI Responsibilities

- Prepare the board before the data team sync meeting.
- Interface with the Department leader you report to in your 1-1, capture the ask and relative prioritization and populate the board.
- Please work on capturing the ask as issues and reorder them for prioritization.
- Issues not of importance or not currently worked on can be below the cutline.
- In the data team sync meeting, ensure that the data team is aware of dependencies and blockers.

### Process

- [Create an issue](https://gitlab.com/gitlab-com/www-gitlab-com/-/issues/new) with `~"Engineering Metrics"` to be added to the [Engineering Metrics](https://gitlab.com/gitlab-com/www-gitlab-com/-/boards/1942495) board.
    - State clearly what are the requirements and measures of the performance indicator.
    - If key performance indicator, apply `~KPI`. If regular performance indicator, apply `~RPI`.
- The [Director of Quality](https://gitlab.com/meks) is the DRI for triage, prioritization, and assignment.
    - If work can be done without the need of new data warehouse capabilities, the DRI will schedule and assign the work within Engineering.
    - If new Data warehouse capabilities are needed from the Data team, a linked issue will be created on the [Data team's Engineering](https://gitlab.com/groups/gitlab-data/-/boards/1496166?label_name%5B%5D=Engineering) board.
        - Requests for support from the Data Team will be reviewed during Data Triage or by [requesting an expedition](https://about.gitlab.com/handbook/business-ops/data-team/how-we-work/#request-to-expedite-responses)
- Every KPI issue is either assigned to the backlog or given a due date. The Engineering team will propose first a due date, which the Results DRI will confirm if possible or the provide the next possible date.
    - Discussions to take place in [#eng-data-kpi](https://gitlab.slack.com/archives/C0166JCH85U) as needed.
- Every new KPI/RPI should follow our [standardized format](/handbook/engineering/performance-indicators/#guidelines).
- The closure of the issue should be done with a merge request to the performance indicator page(s).

## Task management

We have top level boards (at the `gitlab-org` level) to communicate what is being worked on for all teams in quality engineering.
Each board has a cut-line on every column that is owned by an individual. Tasks can be moved vertically to be above or below the cut-line.
The cut-line is used to determine team member capacity, it is assigned to the `Backlog` milestone. The board itself pulls from `any milestone` as a catch-all so we have insights into past, current and future milestones.
The cut-line also serves as a healthy discussion between engineers and their manager in their 1:1s. Every task on the board should be sized according to our [weight definitions](/handbook/engineering/quality/guidelines/#weights).

### How to use the board and cut-line
{:.no_toc}

- Items above the cut-line are issues in-progress and have current priority.
- Items under the cut-line are not being actively worked on.
- Engineers should self-update content in their column, in addition to being aware of their overall assignments before coming to their 1:1s
- Managers should be aware of their overall team assignments. Please review your boards and refine them frequently according to the department goals and business needs.
- Highlight blockers and tasks that are under in weight. Consider adjusting the weights to communicate the challenges/roadblocks broadly. Use `~"workflow::blocked"` to indicate a blocked issue.
- Weight adjustments are a healthy discussion. Sometimes an issue maybe overweight or underweight, this calibration should be an continuous process. Nothing is perfect, we take learnings as feedback to future improvements.
- We aim to have roughly 15 weights assigned to any person at a given time to ensure that engineers are not overloaded and prevent burnout. The number may change due to on-boarding period and etc.

[Discussion on the intent and how to use the board](https://drive.google.com/open?id=1w3z9u_VCvMSpg7OOWvOW17mEMpezi6jH)

### Team boards
{:.no_toc}

- [Dev QE Team](https://gitlab.com/groups/gitlab-org/-/boards/425899)
- [Ops QE Team](https://gitlab.com/groups/gitlab-org/-/boards/978348)
- [Enablement QE Team](https://gitlab.com/groups/gitlab-org/-/boards/978354)
- [Growth QE Team](https://gitlab.com/groups/gitlab-org/-/boards/1512645)
- [Engineering Productivity QE Team](https://gitlab.com/groups/gitlab-org/-/boards/978615)

The boards serve as a single pane of glass view for each team and help in communicating the overall status broadly, transparently and asynchronously.

## Quality Department on-call rotations

### Pipeline triage

Every member in the Quality Department shares the responsibility of analyzing the daily QA tests against `master` and `staging` branches.
More details can be seen [here](/handbook/engineering/quality/guidelines/#quality-department-pipeline-triage-on-call-rotation)

### Incident management

Every manager and director in the Quality Department shares the responsibility of monitoring new and existing incidents
and responding or mitigating as appropriate. Incidents may require review of test coverage, test planning, or updated
procedures, as examples of follow-up work which should be tracked by the DRI.

The Quality Department has a rotation for incident management. The rotation can be seen [here](/handbook/engineering/quality/guidelines/#quality-department-incident-management-on-call-rotation).

**Please note**: Though there is a rotation for DRI, any manager or director within Quality can step in to help in an
urgent situation if the primary DRI is not available. Don't hesitate to reach out in the Slack channel
`#quality-managers`.

## Refinement processes

Below mentioned are few venues of collaboration with [Development](/handbook/engineering/development/) department.

### Bug Refinement

To mitigate high priority issues like [performance bugs](/handbook/engineering/quality/issue-triage/#severity) and [transient bugs](/handbook/engineering/quality/issue-triage/#transient-bugs), Quality Engineering will triage and refine those issues for Product Management and Development via a bi-weekly Bug Refinement process.

#### Goals

- To make the performance of various aspects of our application empirical with tests, environments, and metrics.
- To minimise the [transient bugs](/handbook/engineering/quality/issue-triage/#transient-bugs) seen in our application, thereby improving usability.

#### Identifying Issues

Quality Engineering will do the following in order to identify the issues to be highlighted in the refinement meeting:

- Review existing customer impacting performance bugs [in our issue tracker](https://gitlab.com/groups/gitlab-org/-/issues?scope=all&utf8=%E2%9C%93&state=opened&label_name%5B%5D=performance&label_name%5B%5D=customer&label_name%5B%5D=bug) and add the ~"performance-refinement" label.
- Review issues raised due to failures in the daily performance tests and idenntify early warning on performance degradation which have not had customer exposure but poses a risk in the future. Apply the ~"performance-refinement" label for these issues as well.
- Review all issues labelled as ~"bug::transient".

#### Process

- A manager in the Quality Engineering department will lead refinement with issues populated beforehand in the issue boards.
    - The [performance refinement board](https://gitlab.com/groups/gitlab-org/-/boards/1233204?&label_name%5B%5D=performance-refinement) is used to triage performance issues. 
    - The [transient bugs board](https://gitlab.com/groups/gitlab-org/-/boards/2206756?&label_name%5B%5D=bug%3A%3Atransient) is used to triage transient issues.
- Before each meeting, for issues that are not yet fully triaged, the QEM meeting lead will assign the product manager of the appropriate stage or group to prioritize them with a scheduled milestone.
- The QEM meeting lead should review the board for long running issues that do not have meaningful activity and add them to the agenda to be considered for closure if no longer actionable.
- Any high impact issues which need wider awareness should be added to the agenda for discussion by the relevant stakeholder. This includes urgent performance/transient issues as well as those that have been surfaced as important for customers.
- These issues that are surfaced to the refinement meeting will be severitized and priorotized according to our definitions.
- Guest attendees who may be relevant for a topic on the agenda (product group engineering managers or product managers, technical account managers, support engineers, or others) should be added to the calendar invite.

### Development request issues

Quality Engineering will track productivity, metric and process automation improvement work items
in the [Development-Quality](https://gitlab.com/groups/gitlab-org/-/boards/1262515) board to service the [Development](/handbook/engineering/development/) department.
Requirements and requests are to be created with the label `~dev-quality`. The head of both departments will review and refine the board on an on-going basis.
Issues will be assigned and worked on by an Engineer in the [Engineering Productivity team](engineering-productivity-team) team and [communicated broadly](/handbook/engineering/quality/triage-operations/#communicate-early-and-broadly-about-expected-automation-impact) when each work item is completed.

### Release process overview

Moved to [release documentation](https://gitlab.com/gitlab-org/release/docs/).

### Security Questionnaires

The Quality department collaborates with the [Security department's compliance team](/handbook/engineering/security/#security-compliance) to handle requests from customers and prospects.

The Risk and Field Security team maintains the current state of answers to these questions, please follow the process to [request completion of assessment questionnaire](/handbook/engineering/security/security-assurance/risk-field-security/customer-security-assessment-process.html).

If additional input is needed from the Quality team, the DRI for this is the Director of Quality. Tracking of supplemental requests will be via a confidential issue in the [compliance issue tracker](https://gitlab.com/gitlab-com/gl-security/security-assurance/sec-compliance/compliance). Once the additional inputs have been supplied, this is stored in the Compliance team's domain for efficiency.

## Department recurring event DRIs

| Recurring event | Primary DRI | Backup DRI | Cadence | Format |
| --------------- | ----------- | ---------- | ------- | ------ |
| Engineering Key review | `@meks` | `@kwiebers` | Every 4 weeks | Review meeting |
| Group conversation | `@meks` | Rotation between: `@at.ramya` <br>`@tpazitny` <br>`@kwiebers` <br>`@jo_shih` <br>`@vincywilson` | Every 8 weeks | [Group Conversations](#group-conversations) |
| Product Stage Group conversation Content | `@at.ramya` Dev<br>`@jo_shih` Ops<br>`@tpazitny` Enablement<br>`@tpazitny` Secure<br>`@vincywilson` Growth<br>`@vincywilson` Protect |  | Every 8 weeks | [Quality team OKR slide contributions](#counterpart-product-stage-gcs) to the counterpart product section |
| [GitLab SaaS Infrastructure Weekly](/handbook/engineering/infrastructure/#gitlab-saas-infrastructure) | QEM rotation between `@jo_shih` <br>`@tpazitny` <br>`@vincywilson` | `@meks` | Weekly | Incident review and corrective action tracking |
| [Incident management](/handbook/engineering/infrastructure/incident-management/) | Rotates between @jo_shih, @tpazitny, and @vincywilson | All managers | Weekly | Incident monitoring, response, and management as needed to represent Quality |
| [Self-managed environment triage](/handbook/engineering/quality/sec-enablement-qe-team/#self-managed-environment-triage) | `@tpazitny` | `TBD` | Every 2 weeks | Sync stand-up |
| [Performance refinement](/handbook/engineering/quality/#performance-issues) | `@at.ramya` | `@tpazitny` | Every 2 weeks | Review meeting |
| Security Vulnerability review | `@meks` | `TBD` | Every 4 weeks | Review meeting |
| Quality Engineering Staff | `@meks` | `TBD` | Weekly | Review meeting |
| Quality Engineering Bi-Weekly | All managers | `TBD` | Every 2 weeks | Review meeting |
| Ops section stakeholder review | `@jo_shih` | `@kwiebers` <br>`@zeffmorgan` | Every 4 weeks | Review meeting |
| Quality Department Social Call | All team members | All team members | Every 2 weeks | Meet and Greet |

## Quality Engineering initiatives

### Triage Efficiency

Due to the volume of issues, one team cannot handle the triage process.
We have invented [Triage Reports](/handbook/engineering/quality/triage-operations/#triage-reports) to scale the triage process within Engineering horizontally.

More on our [Triage Operations](/handbook/engineering/quality/triage-operations/)

### Test Automation Framework

The GitLab test automation framework is distributed across two projects:

- [GitLab QA], the test orchestration tool.
- The scenarios and spec files within the GitLab codebase under `/qa` in [GitLab].

#### Installation and execution

- Install and set up the [GitLab Development Kit](https://gitlab.com/gitlab-org/gitlab-development-kit)
- Install and run [GitLab QA] to kick off test execution.
    - The spec files (test cases) can be found in the [GitLab codebase](https://gitlab.com/gitlab-org/gitlab/tree/master/qa)

#### Documentation and videos

- [GitLab QA Documentation](https://gitlab.com/gitlab-org/gitlab-qa/blob/master/docs)
- [Architecture overview](https://gitlab.com/gitlab-org/gitlab-qa/blob/master/docs/architecture.md)
- [End-to-end testing at GitLab](https://docs.gitlab.com/ee/development/testing_guide/end_to_end/index.html)
- [What tests can be run with GitLab QA](https://gitlab.com/gitlab-org/gitlab-qa/-/blob/master/docs/what_tests_can_be_run.md)
- (Video) [GitLab Automated Test Suite Overview](https://youtu.be/r0ZicFxtfgI)
- (Video) [Orchestrated end-to-end tests at GitLab - Part 1](https://youtu.be/wWC7r3l0u1Y)
- (Video) [Orchestrated end-to-end tests at GitLab - Part 2](https://youtu.be/U8zCle_Up6I)
- (Video) [How to use GitLab QA to test a self-managed GitLab instance](https://youtu.be/VpT6fF6kO_U)
- (Video) [How to run an end-to-end test interactively (debugging)](https://youtu.be/SO2U8gpLSeM)

### Performance and Scalability

The Quality Department is committed to ensuring that self-managed customers have performant and scalable configurations.
To that end, we are focused on creating a variety of tested and certified [Reference Architectures]. Additionally, we
have developed the [GitLab Performance Tool], which provides several tools for measuring the performance of any GitLab
instance. We use the Tool every day to monitor for potential performance degradations, and this tool can also be used
by GitLab customers to directly test their on-premise instances. More information is available on our
[Performance and Scalability](/handbook/engineering/quality/performance-and-scalability/) page.

### MRARR

The Quality department is the DRI for [MRARR](/handbook/engineering/performance-indicators/#mrarr) tooling and tracking. MRARR is an important part of the [Open Core 3 year strategy](/company/strategy/#2-build-on-our-open-core-strength) to increase contributions from the Wider community.

#### Customer contributor tracking

Customer contributors are currently tracked in [a Google Sheet](https://docs.google.com/spreadsheets/d/1yIASbQOS2TcHIFmSW_e3xTiQzgkYSLSgiujFJ7Dg834/edit#gid=447581669) that is imported to Sisense every day. Data has been sourced from Bitergia and reviewing previous Wider community contributions.

#### Customer contributor additions

Additions have been identified through the following means and added to the source above once confirmed by a Manager in the Quality Department.

1. Indication from a member of the Sales team
1. Contributor is linked to a Salesforce contact
1. Confirmation with other public sources
    - Identifying the organization, commit email or other public user information on the merge request.
    - Validating that contributor is associated with a customer organization by using other public sources such as LinkedIn.
    - Verify the organization is a paying customer of GitLab in using Salesforce.com to open the Account and look at the CARR fields.

After verifying a contributor is associated with a customer, these steps are how to add a new contributor to the tracking [sheet](https://docs.google.com/spreadsheets/d/1yIASbQOS2TcHIFmSW_e3xTiQzgkYSLSgiujFJ7Dg834/edit#gid=447581669)

1. Check if the customer organization is already defined in the spreadsheet by the Salesforce Account ID. If not, add a new row with the following information:
    - Salesforce Account name for the Contributor Organization (a)
    - Full 18 character Salesforce Account ID for the SFDC Account ID column (c). This can be retrieved from converting the 15 character ID with a gem like `salesforce_id_formatter`
1. Add the Contributor's GitLab.com username to the Contributor Usernames column (b). **The format of this column is a JSON array. Please use doublequoted strings and commas after each username.**

#### Diagnostic dashboard

The [MRARR Diagnostics](https://app.periscopedata.com/app/gitlab/790656/) dashboard contains some helpful supplemental charts to understand changes in MRARR and untracked contributors.

## Other related pages

- [Issue Triage Policies](/handbook/engineering/quality/issue-triage/)
- [Performance of GitLab](/handbook/engineering/performance/)
- [Monitoring of GitLab.com](/handbook/engineering/monitoring/)
- [Production Readiness Guide](https://gitlab.com/gitlab-com/infrastructure/blob/master/.gitlab/issue_templates/production_readiness.md)

[GitLab QA]: https://gitlab.com/gitlab-org/gitlab-qa
[GitLab Insights]: https://gitlab.com/gitlab-org/gitlab-insights
[GitLab Performance Tool]: https://gitlab.com/gitlab-org/quality/performance
[GitLab Triage]: https://gitlab.com/gitlab-org/gitlab-triage
[GitLab]: https://gitlab.com/gitlab-org/gitlab
[Reference Architectures]: https://docs.gitlab.com/ee/administration/reference_architectures/index.html
